# 	ForgtAI : International Workshop on Forging Trust in Artificial Intelligence
Collocated with the _International Joint Conference on Neural Networks (IJCNN) 2025, 30/6-5/7 2025, ROME_

Establishing and upholding trust in AI systems is an imperative pursuit as Machine Learning becomes intricately interwoven into our daily lives. The workshop, "Forging Trust in Artificial Intelligence" brings together a group of experts and researchers from diverse subfields, converging on the exploration of how transparency, fairness, privacy, and security collectively contribute to making machine learning trustworthy. By uniting experts across these pivotal disciplines, this workshop illuminates the best practices that not only enhance the trustworthiness of AI but also reinforce its ethical foundations.

Ensuring trust in machine learning is necessary for unlocking its potential while minimizing risks. This is especially true in the current environment, where the constant expansion of data sources aligns with a growing interest in using them to develop comprehensive and universally applicable AI systems. This interest highlights the need to address issues related to transparency, fairness, privacy and security, particularly in the area of multimodal learning, where various data types and learners are combined to create sophisticated, but often opaque AI systems.

Within this context, establishing best practices for data integration is essential to ensure transparency and interpretability of AI systems based on diverse learners. Fairness considerations, on the other hand, may involve identifying and addressing potential biases from different modalities. This includes exploring approaches to mitigate their impact and leveraging fair representation learning when integrating information from sources with varying bias levels. By addressing such issues alongside data privacy and security concerns, this workshop aims to contribute to the development of ethical, transparent, and secure AI that has a positive impact on our global societyâ€™s well-being.

The following list includes (but is not limited to) relevant topics that will be addressed within this workshop:  

## Interpretability in ML and NLP Models

Interpretable Natural Language Processing Models
Visual Explanations for Language Models
Techniques for model transparency and interpretability
Interpretability in Multimodal Learning
Privacy and Security

## Algorithmic Fairness in Machine Learning

Fairness Evaluation and Metrics in ML
Ethical AI Development and Deployment
Bias Mitigation in AI
Fairness in Multimodal Learning
Fairness in Collaborative Learning
Transparency and Fairness in Federated Learning
Explainable and Fair AI Models

## Privacy-Preserving Machine Learning and Data Sharing

Privacy-Preserving Data Anonymization Techniques
Federated Learning and Privacy
Homomorphic Encryption for Secure ML
Privacy-Preserving Clustering and Classification
Differential Privacy in Machine Learning
ML for Security and Adversarial Attacks
Fairness and Ethical Development


# Organisers

### Alexandros Iosifidis, Tampere University, Finland
### Nistor Grozavu, Cergy Paris University, France
### Aikaterini Tzompanaki, Cergy Paris University, France
### Corina Besliu, Technical University of Moldova, Moldova
### Nicoleta Rogovschi,  Paris Descartes University, France

# Paper Submission
## Submission guidelines
We accept full or short paper submissions. Full paper submissions (up to 8 pages) will be considered for publication in the IJCNN 2025 proceedings on the IEEE Xplore Digital Library. Short papers (up to 4 pages) will be considered as poster presentations at the conference; however, these will not be included in the proceedings. Papers must be submitted through the IJCNN 2025 CMT System.
## Deadline: 20/03/2025

# Program Committee
TBA

# Sponsors
The workshop is organised under the support of the PANDORA European project https://pandora-heu.eu/
