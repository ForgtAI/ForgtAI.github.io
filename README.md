# 	ForgtAI : International Workshop on Forging Trust in Artificial Intelligence
 
Establishing and upholding trust in AI systems is an imperative pursuit as Machine Learning becomes intricately interwoven into our daily lives. The workshop, "Forging Trust in Artificial Intelligence" brings together a group of experts and researchers from diverse subfields, converging on the exploration of how transparency, fairness, privacy, and security collectively contribute to making machine learning trustworthy. By uniting experts across these pivotal disciplines, this workshop illuminates the best practices that not only enhance the trustworthiness of AI but also reinforce its ethical foundations.

Ensuring trust in machine learning is necessary for unlocking its potential while minimizing risks. This is especially true in the current environment, where the constant expansion of data sources aligns with a growing interest in using them to develop comprehensive and universally applicable AI systems. This interest highlights the need to address issues related to transparency, fairness, privacy and security, particularly in the area of multimodal learning, where various data types and learners are combined to create sophisticated, but often opaque AI systems.

Within this context, establishing best practices for data integration is essential to ensure transparency and interpretability of AI systems based on diverse learners. Fairness considerations, on the other hand, may involve identifying and addressing potential biases from different modalities. This includes exploring approaches to mitigate their impact and leveraging fair representation learning when integrating information from sources with varying bias levels. By addressing such issues alongside data privacy and security concerns, this workshop aims to contribute to the development of ethical, transparent, and secure AI that has a positive impact on our global society’s well-being.

The following list includes (but is not limited to) relevant topics that will be addressed within this workshop:  

## Interpretability in ML and NLP Models
 <ul>
              <li>Interpretable Natural Language Processing Models</li>
              <li>Visual Explanations for Language Models</li>
              <li>Techniques for model transparency and interpretability</li>
              <li>Interpretability in Multimodal Learning</li>
              <li>Privacy and Security</li>
  </ul> 

## Algorithmic Fairness in Machine Learning
 <ul>
              <li>Fairness Evaluation and Metrics in ML</li>
              <li>Ethical AI Development and Deployment</li>
              <li>Bias Mitigation in AI</li>
              <li>Fairness in Multimodal Learning</li>
              <li>Fairness in Collaborative Learning</li>
              <li>Transparency and Fairness in Federated Learning</li>
              <li>Explainable and Fair AI Models</li>

  </ul> 

## Privacy-Preserving Machine Learning and Data Sharing
 <ul>
              <li>Privacy-Preserving Data Anonymization Techniques</li>
              <li>Federated Learning and Privacy</li>
              <li>Homomorphic Encryption for Secure ML</li>
              <li>Differential Privacy in Machine Learning</li>
              <li>ML for Security and Adversarial Attacks</li>
              <li>Fairness and Ethical Development</li>

  </ul> 

<hr>

# Keynote Speaker
TBA




<hr>

# Paper Submission

We accept full or short paper submissions. Full paper submissions (up to 8 pages) will be considered for publication in the IJCNN 2025 proceedings on the IEEE Xplore Digital Library, and will be oraly presented during the workshop. Short papers and extended abstracts (up to 4 pages) will be considered for oral presentations or poster presentations at the workshop; however, these will not be included in the proceedings. Papers must be submitted through the IJCNN 2025 CMT System. For submission guidelines please check [here](https://2025.ijcnn.org/authors/initial-author-instructions).
## Submission Deadline: 20/03/2025
## Acceptance Notification: 15/04/2025

<hr>

# Organisers

**Alexandros Iosifidis, Tampere University, Finland**<br>
**Nistor Grozavu, Cergy Paris University, France**<br>
**Aikaterini Tzompanaki, Cergy Paris University, France**<br>
**Corina Besliu, Technical University of Moldova, Moldova** <br>
**Nicoleta Rogovschi,  Paris Descartes University, France**<br>

<hr>

# Program Committee

**Dimitris Sacharidis, Université Libre de Bruxelles, Belgium**<br>
**Illia Oleksiienko, Aarhus University, Denmark**<br>
**Nikos Passalis, Aristotle University of Thessaloniki, Greece**<br>
TBC
<hr>

# Sponsors
The workshop is organised under the support of the [PANDORA](https://pandora-heu.eu/) European project.

<hr>

#### Contact: aikaterini.tzompanaki@cyu.fr ; corina.besliu@ati.utm.md
