<h1>	ForgtAI : International Workshop on Forging Trust in Artificial Intelligence </h1>
 
Establishing and upholding trust in AI systems is an imperative pursuit as Machine Learning becomes an everyday commodity in our lives. The workshop "Forging Trust in Artificial Intelligence" brings together a group of experts and researchers from diverse subfields, converging on the exploration of how transparency, explainability, fairness, and privacy collectively contribute to making machine learning trustworthy. By uniting experts across these pivotal disciplines, this workshop illuminates the best practices that not only enhance the trustworthiness of AI but also reinforce its ethical foundations. Building on the success of the last year’s workshop, which focused on explainability and security in vision AI, this year’s event shifts its attention to the challenges of managing _sequential and multimodal data in NLP and IoT_. These areas are at the forefront of human-AI interaction: large language models (LLMs) already shape how we access information and make decisions,  while smart IoT systems increasingly define automated processes that directly affect not only the industry but also our everyday lives.

This year’s workshop highlights explainability as a cornerstone of trustworthy AI in continuous systems. It tackles the complexities of understanding how neural networks operate, from demystifying the outputs of LLMs to clarifying automated decisions in continuous IoT environments, and eventually providing more tools to improving AI performance.  Ensuring fairness and mitigating biases are also central themes, as these systems increasingly influence critical aspects of human life. By focusing on transparency and ethical practices, the ForgAI Workshop seeks to equip participants with actionable insights and methodologies for building AI systems that inspire confidence and align with societal values.
By aligning with IJCNN’s mission to explore the latest advancements in neural networks, the workshop deepens the conversation around responsible AI development. It emphasizes that explainability is not just a technical challenge but a fundamental requirement for creating AI systems that serve as reliable and ethical partners in human-AI interactions.


The following list includes (but is not limited to) relevant topics that will be addressed within this workshop:  

<h2> Explainability in ML and NLP Models </h2>
 <ul>
              <li>Explainable Natural Language Processing Models</li>
              <li>Visual Explanations for Language Models</li>
              <li>Explainable Large Language Models</li>               
              <li>Interpretable Architectures for Large Language Models</li>
              <li>Techniques for model transparency and interpretability</li>
              <li>Explainability in Multimodal Learning</li>
              <li>Privacy and Security</li>
  </ul> 

<h2> Explainability in AIoT (Artificial Intelligence in IoT)</h2>
 <ul>
              <li>Interpretable Machine Learning Models for IoT Data</li>
              <li>Explainable Anomaly Detection in IoT Networks</li>
              <li>Explainability for Federated Learning in IoTL</li>
              <li>Causal Inference and Explainability in IoT Applications</li>
              <li>Human-Centric Explainability in IoT</li>
              <li>Continual Learning and Explainability</li>
              <li>Explainable Predictive Maintenance</li>

  </ul> 

<h2> Algorithmic Fairness in Machine Learning</h2>
 <ul>
              <li>Fairness Evaluation and Metrics in ML</li>
              <li>Ethical AI Development and Deployment</li>
              <li>Bias Mitigation in AI</li>
              <li>Fairness in Multimodal Learning</li>
              <li>Fairness in Collaborative Learning</li>
              <li>Transparency and Fairness in Federated Learning</li>
              <li>Explainable and Fair AI Models</li>

  </ul> 



<hr>

<h1> Invited Speakers</h1>

**Professor Vassilis Christophides, ENSEA/ETIS, France** <br>
and<br> 
**Professor Anastasios Tefas,  Aristotle University of Thessaloniki, Greece**<br>
**Title**: Trustworthiness in AI and Autonomous Systems<br>
**Short Bio**: Anastasios Tefas received the B.Sc. in informatics in 1997 and the Ph.D. degree in informatics in 2002, both from the Aristotle University of Thessaloniki, Greece. Since 2022 he has been a Professor at the Department of Informatics, Aristotle University of Thessaloniki. From 2008 to 2022, he was a Lecturer, Assistant Professor, Associate Professor at the same University. He is the director of the MSc program on Artificial Intelligence in the Dept. of Informatics. Prof. Tefas coordinated 16 and participated in 20 research projects financed by national, private and European funds. He was the Coordinator of the H2020 project OpenDR, “Open Deep Learning Toolkit for Robotics”. He has co-authored 160 journal papers, 300 papers in international conferences and contributed 17 chapters to edited books in his area of expertise. He has co-organized more than 15 workshops, tutorials, special sessions, and special issues and has given more than 20 invited talks. He has co-edited the book “Deep Learning for Robot Perception and Cognition”, Elsevier, 2022. Over 13000 citations have been recorded to his publications and his H-index is 55 according to Google scholar. His current research interests include computational intelligence, deep learning, machine learning, data analysis and retrieval, computer vision, autonomous systems and robotics.
<br>

<hr>

<h1> Paper Submission</h1>

We accept full or short paper submissions. **Full paper submissions (up to 8 pages)** will be considered for **publication in the IJCNN 2025 proceedings on the IEEE Xplore Digital Library**, and will be oraly presented during the workshop. Full papers must follow the same author guidelines ([check here](https://2025.ijcnn.org/authors/initial-author-instructions)) as the papers of the main conference (double blind), and will be reviewed by 3 reviwers of our program committee. **Short papers and extended abstracts (up to 4 pages)** will be considered for oral presentations or poster presentations at the workshop; however, these will not be included in the proceedings. Papers must be submitted through the [IJCNN 2025 CMT System](https://cmt3.research.microsoft.com/IJCNN2025/Track/3/Submission/Create), by selecting the workshop name 'International Workshop on Forging Trust in Artificial Intelligence 2025' in the Subject Area.  
## Submission Deadline: 20/03/2025
## Acceptance Notification: 15/04/2025

<hr>

<h1> Organisers</h1>

**Alexandros Iosifidis, Tampere University, Finland**<br>
**Nistor Grozavu, Cergy Paris University/ETIS, France**<br>
**Aikaterini Tzompanaki, Cergy Paris University/ETIS, France**<br>
**Corina Besliu, Technical University of Moldova, Moldova** <br>
**Nicoleta Rogovschi,  Paris Descartes University, France**<br>

<hr>

<h1> Program Committee</h1>

**Hajer Baazaoui, CY Cergy Paris University/ETIS, France**<br>
**Georgios Bouloukakis, Télécom SudParis/IP-Paris, France**<br>
**Luis Galárraga, INRIA/IRISA, France**<br>
**Apostolos Giannoulidis, Aristotle University of Thessaloniki, Greece**<br>
**Michele Linardi,CY Cergy Paris University/ETIS, France**<br> 
**Illia Oleksiienko, Aarhus University, Denmark**<br>
**Nikolaos Passalis, Aristotle University of Thessaloniki, Greece**<br>
**Dimitris Sacharidis, Université Libre de Bruxelles, Belgium**<br>
**Konstantinos Stefanidis, Tampere University, Finland**<br>

<hr>

<h1> Sponsors</h1>
The workshop is organised under the support of the [PANDORA](https://pandora-heu.eu/) European project and the german company [OTRS GmbH](https://otrs.com/de/home/).

<hr>

<h4> Contact: aikaterini.tzompanaki@cyu.fr ; corina.besliu@ati.utm.md </h4>
